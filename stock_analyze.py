import streamlit as st
import gspread
import pandas as pd
import yfinance as yf
import requests
import urllib3
import os
import time
from datetime import datetime
from google.oauth2.service_account import Credentials

# --- åŸºç¤é…ç½® ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
SHEET_NAME = "Stock_Predictions_History"

def get_gspread_client():
    """å®‰å…¨æˆæ¬Šé‚è¼¯"""
    scopes = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive'
    ]
    
    # å„ªå…ˆå¾ Streamlit Secrets è®€å– (é›²ç«¯ç’°å¢ƒ)
    if "gcp_service_account" in st.secrets:
        try:
            creds_info = st.secrets["gcp_service_account"]
            creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
            return gspread.authorize(creds)
        except Exception as e:
            st.error(f"Cloud Auth Error: {e}")
            return None
    # æœ¬åœ°æ¸¬è©¦å‚™æ¡ˆ
    elif os.path.exists("eco-precept-485904-j5-7ef3cdda1b03.json"):
        creds = Credentials.from_service_account_file("eco-precept-485904-j5-7ef3cdda1b03.json", scopes=scopes)
        return gspread.authorize(creds)
    return None

def get_hot_stocks_from_yahoo_bs4(limit=100):
    """ä½¿ç”¨ BeautifulSoup è§£æ Yahoo è‚¡å¸‚æˆäº¤å€¼æ’è¡Œæ¦œ (ä¸éœ€è¦ html5lib)"""
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        st.error("ç¼ºå°‘ beautifulsoup4 å¥—ä»¶ï¼Œè«‹å®‰è£: pip install beautifulsoup4")
        return None
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    hot_tickers = []
    
    try:
        st.info("ğŸ” æ­£åœ¨å¾ Yahoo è‚¡å¸‚æŠ“å–æˆäº¤å€¼æ’è¡Œæ¦œ...")
        url = "https://tw.stock.yahoo.com/rank/turnover?exchange=TAI"
        r = requests.get(url, headers=headers, timeout=10)
        
        if r.status_code != 200:
            raise Exception(f"HTTP ç‹€æ…‹ç¢¼: {r.status_code}")
        
        # ä½¿ç”¨ BeautifulSoup è§£æ (ä½¿ç”¨å…§å»ºçš„ html.parser)
        soup = BeautifulSoup(r.text, 'html.parser')
        
        # Yahoo çš„æ’è¡Œæ¦œé€šå¸¸åœ¨ç‰¹å®šçš„ div æˆ– table ä¸­
        # å˜—è©¦æ‰¾åˆ°æ‰€æœ‰åŒ…å«è‚¡ç¥¨ä»£è™Ÿçš„é€£çµæˆ–æ–‡å­—
        
        # æ–¹æ³• 1: æ‰¾å°‹æ‰€æœ‰å¯èƒ½æ˜¯è‚¡ç¥¨ä»£è™Ÿçš„ 4 ä½æ•¸å­—
        import re
        text_content = soup.get_text()
        # æ‰¾å‡ºæ‰€æœ‰ 4 ä½æ•¸å­—
        potential_tickers = re.findall(r'\b(\d{4})\b', text_content)
        
        # éæ¿¾ï¼šåªä¿ç•™å°è‚¡å¸¸è¦‹çš„ä»£è™Ÿç¯„åœ (1000-9999)
        for ticker in potential_tickers:
            ticker_num = int(ticker)
            if 1000 <= ticker_num <= 9999 and f"{ticker}.TW" not in hot_tickers:
                hot_tickers.append(f"{ticker}.TW")
                if len(hot_tickers) >= limit:
                    break
        
        if len(hot_tickers) > 0:
            st.success(f"âœ… æˆåŠŸå¾ Yahoo æŠ“å– {len(hot_tickers)} æª”è‚¡ç¥¨")
            return hot_tickers
        else:
            raise Exception("æœªèƒ½è§£æå‡ºä»»ä½•è‚¡ç¥¨ä»£è™Ÿ")
            
    except Exception as e:
        st.warning(f"âš ï¸ Yahoo çˆ¬èŸ²å¤±æ•—: {e}")
        return None

def get_hot_stocks_from_yahoo_lxml(limit=100):
    """ä½¿ç”¨ lxml è§£æå™¨ (pd.read_html çš„æ›¿ä»£æ–¹æ¡ˆ)"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    try:
        st.info("ğŸ” æ­£åœ¨å¾ Yahoo è‚¡å¸‚æŠ“å–æˆäº¤å€¼æ’è¡Œæ¦œ (ä½¿ç”¨ lxml)...")
        url = "https://tw.stock.yahoo.com/rank/turnover?exchange=TAI"
        r = requests.get(url, headers=headers, timeout=10)
        
        # ä½¿ç”¨ lxml è§£æå™¨
        dfs = pd.read_html(r.text, flavor='lxml')
        
        if not dfs or len(dfs) == 0:
            raise Exception("ç„¡æ³•è§£æç¶²é è¡¨æ ¼")
        
        df = dfs[0]
        
        # æ™ºæ…§åµæ¸¬åŒ…å«è‚¡åçš„æ¬„ä½
        target_col = None
        for i, col_name in enumerate(df.columns):
            col_str = str(col_name).lower()
            if 'è‚¡' in col_str or 'å' in col_str or 'ä»£è™Ÿ' in col_str or 'symbol' in col_str:
                target_col = i
                break
        
        if target_col is None:
            target_col = 1  # é è¨­ç¬¬äºŒæ¬„
        
        hot_tickers = []
        for item in df.iloc[:, target_col]:
            item_str = str(item).strip()
            
            # å˜—è©¦åˆ‡å‰²å‡ºä»£è™Ÿ
            parts = item_str.split()
            ticker = parts[0] if parts else ""
            
            # åªè¦ 4 ä½æ•¸å­—
            if ticker.isdigit() and len(ticker) == 4:
                hot_tickers.append(f"{ticker}.TW")
                if len(hot_tickers) >= limit:
                    break
        
        if hot_tickers:
            st.success(f"âœ… æˆåŠŸå¾ Yahoo æŠ“å– {len(hot_tickers)} æª”è‚¡ç¥¨")
            return hot_tickers
        else:
            raise Exception("æœªèƒ½è§£æå‡ºä»»ä½•è‚¡ç¥¨ä»£è™Ÿ")
            
    except Exception as e:
        st.warning(f"âš ï¸ Yahoo çˆ¬èŸ² (lxml) å¤±æ•—: {e}")
        return None

def get_fallback_list(limit):
    """å‚™ç”¨è‚¡ç¥¨æ¸…å–® - æ‰‹å‹•ç¶­è­·çš„ç†±é–€è‚¡"""
    fallback = [
        # --- æ¬Šå€¼/åŠå°é«” ---
        "2330.TW", "2454.TW", "2317.TW", "2303.TW", "2308.TW", "2382.TW", "3231.TW", "3443.TW", "3661.TW", "3035.TW",
        # --- AI ä¼ºæœå™¨/æ•£ç†± ---
        "2376.TW", "2356.TW", "6669.TW", "3017.TW", "3324.TW", "2421.TW", "3037.TW", "2368.TW", "2449.TW", "6271.TW",
        # --- èˆªé‹/å‚³ç”¢ ---
        "2603.TW", "2609.TW", "2615.TW", "2618.TW", "2610.TW", "1513.TW", "1519.TW", "1504.TW", "1605.TW", "2002.TW",
        # --- é‡‘è ---
        "2881.TW", "2882.TW", "2891.TW", "2886.TW", "2884.TW", "2887.TW", "2892.TW", "2880.TW", "2883.TW", "2890.TW",
        # --- å…‰é›»/é¢æ¿ ---
        "2409.TW", "3481.TW", "3008.TW", "2481.TW", "2344.TW", "2408.TW", "6770.TW", "5347.TW", "4961.TW", "9958.TW",
        # --- é›»å­é›¶çµ„ä»¶ ---
        "2357.TW", "2379.TW", "2395.TW", "2412.TW", "2474.TW", "3189.TW", "3711.TW", "4904.TW", "6505.TW", "8046.TW",
        # --- é›»è…¦å‘¨é‚Š ---
        "2301.TW", "2324.TW", "2353.TW", "2377.TW", "2392.TW", "3045.TW", "6239.TW", "6415.TW", "6669.TW", "8299.TW",
        # --- é€šä¿¡ç¶²è·¯ ---
        "2347.TW", "2393.TW", "2439.TW", "3044.TW", "3706.TW", "4938.TW", "6176.TW", "6531.TW", "8410.TW", "8454.TW",
        # --- å…¶ä»–é›»å­ ---
        "2323.TW", "2327.TW", "2337.TW", "2345.TW", "2351.TW", "2362.TW", "2371.TW", "2385.TW", "2404.TW", "2434.TW"
    ]
    st.info(f"ğŸ›¡ï¸ ä½¿ç”¨å‚™ç”¨æ¸…å–®: {len(fallback[:limit])} æª”ç²¾é¸è‚¡ç¥¨")
    return fallback[:limit]

def get_hot_stocks(limit=100, force_fallback=False):
    """æ•´åˆæ–¹æ³•ï¼šå˜—è©¦å¤šç¨®è§£ææ–¹å¼"""
    
    if force_fallback:
        return get_fallback_list(limit)
    
    # æ–¹æ³• 1: å˜—è©¦ lxml è§£æå™¨
    tickers = get_hot_stocks_from_yahoo_lxml(limit)
    if tickers and len(tickers) > 0:
        return tickers
    
    # æ–¹æ³• 2: å˜—è©¦ BeautifulSoup
    tickers = get_hot_stocks_from_yahoo_bs4(limit)
    if tickers and len(tickers) > 0:
        return tickers
    
    # æ–¹æ³• 3: ä½¿ç”¨å‚™ç”¨æ¸…å–®
    st.warning("âš ï¸ æ‰€æœ‰çˆ¬èŸ²æ–¹æ³•å‡å¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®")
    return get_fallback_list(limit)

def download_stock_data(tickers, period="1y"):
    """æ‰¹æ¬¡ä¸‹è¼‰è‚¡ç¥¨è³‡æ–™"""
    try:
        with st.spinner(f"ğŸ“¥ æ­£åœ¨ä¸‹è¼‰ {len(tickers)} æª”è‚¡ç¥¨è³‡æ–™ (period={period})..."):
            data = yf.download(
                tickers, 
                period=period, 
                group_by='ticker', 
                auto_adjust=True, 
                threads=True,
                progress=False
            )
        
        if data.empty:
            st.error("ä¸‹è¼‰çš„è³‡æ–™ç‚ºç©º")
            return None
        
        # ç§»é™¤å®Œå…¨ç©ºç™½çš„æ¬„ä½
        data = data.dropna(axis=1, how='all')
        st.success(f"âœ… æˆåŠŸä¸‹è¼‰ {len(tickers)} æª”è‚¡ç¥¨è³‡æ–™")
        return data
        
    except Exception as e:
        st.error(f"ä¸‹è¼‰å¤±æ•—: {e}")
        return None

def calculate_trading_values(tickers, data):
    """è¨ˆç®—æ¯æ”¯è‚¡ç¥¨çš„äº¤æ˜“å€¼æŒ‡æ¨™"""
    results = []
    errors = []
    
    for ticker in tickers:
        try:
            # è™•ç†å¤šæ¨™çš„ä¸‹è¼‰çš„è³‡æ–™çµæ§‹
            if isinstance(data.columns, pd.MultiIndex):
                if ticker not in data.columns.get_level_values(0):
                    errors.append(f"{ticker}: æœªåœ¨ä¸‹è¼‰è³‡æ–™ä¸­")
                    continue
                ticker_data = data[ticker].dropna()
            else:
                ticker_data = data.dropna()
            
            if ticker_data.empty:
                errors.append(f"{ticker}: è³‡æ–™ç‚ºç©º")
                continue
            
            # å–æœ€æ–°ä¸€ç­†è³‡æ–™
            last_row = ticker_data.iloc[-1]
            
            # æª¢æŸ¥å¿…è¦æ¬„ä½
            if 'Close' not in ticker_data.columns or 'Volume' not in ticker_data.columns:
                errors.append(f"{ticker}: ç¼ºå°‘å¿…è¦æ¬„ä½")
                continue
            
            price = float(last_row['Close'])
            volume = float(last_row['Volume'])
            
            # éæ¿¾ç„¡æ•ˆè³‡æ–™
            if price <= 0 or volume <= 0:
                errors.append(f"{ticker}: åƒ¹æ ¼æˆ–æˆäº¤é‡ç„¡æ•ˆ")
                continue
            
            # è¨ˆç®—äº¤æ˜“å€¼ (å„„å…ƒ)
            trading_value = (price * volume) / 1e8
            
            results.append({
                "æ—¥æœŸ": datetime.now().strftime('%Y-%m-%d'),
                "è‚¡ç¥¨ä»£è™Ÿ": ticker,
                "æ”¶ç›¤åƒ¹æ ¼": round(price, 2),
                "æˆäº¤é‡": int(volume),
                "äº¤æ˜“å€¼æŒ‡æ¨™": round(trading_value, 4)
            })
            
        except Exception as e:
            errors.append(f"{ticker}: {str(e)[:50]}")
            continue
    
    return results, errors

# --- Streamlit UI ---
st.title("ğŸ† å°è‚¡ç†±é–€è‚¡è³‡é‡‘æ’è¡Œç³»çµ±")
st.write("**æ™ºæ…§æµç¨‹ï¼š** Yahoo æˆäº¤æ¦œ â†’ æ‰¹æ¬¡ä¸‹è¼‰ â†’ è¨ˆç®—äº¤æ˜“å€¼ â†’ æ’åºå‰ 100 â†’ åŒæ­¥é›²ç«¯")

# æª¢æŸ¥å¥—ä»¶ç‹€æ…‹
with st.expander("ğŸ”§ å¥—ä»¶æª¢æŸ¥"):
    packages_status = []
    
    try:
        import lxml
        packages_status.append("âœ… lxml - å·²å®‰è£")
    except:
        packages_status.append("âŒ lxml - æœªå®‰è£ (å»ºè­°å®‰è£)")
    
    try:
        from bs4 import BeautifulSoup
        packages_status.append("âœ… beautifulsoup4 - å·²å®‰è£")
    except:
        packages_status.append("âŒ beautifulsoup4 - æœªå®‰è£ (å»ºè­°å®‰è£)")
    
    try:
        import html5lib
        packages_status.append("âœ… html5lib - å·²å®‰è£")
    except:
        packages_status.append("âš ï¸ html5lib - æœªå®‰è£ (å¯é¸)")
    
    for status in packages_status:
        st.write(status)
    
    st.write("")
    st.write("**å®‰è£æŒ‡ä»¤ï¼š**")
    st.code("pip install lxml beautifulsoup4 html5lib")

# åƒæ•¸è¨­å®š
col1, col2, col3 = st.columns(3)
with col1:
    target_count = st.number_input("ç›®æ¨™è‚¡ç¥¨æ•¸é‡", min_value=10, max_value=200, value=100, step=10)
with col2:
    data_period = st.selectbox("è³‡æ–™æœŸé–“", ["5d", "1mo", "3mo", "6mo", "1y"], index=0)
with col3:
    use_fallback = st.checkbox("å¼·åˆ¶ä½¿ç”¨å‚™ç”¨æ¸…å–®", value=False)

if st.button("ğŸš€ é–‹å§‹åŸ·è¡Œåˆ†æ"):
    # æ­¥é©Ÿ 1: ç²å–è‚¡ç¥¨æ¸…å–®
    st.subheader("ğŸ“‹ æ­¥é©Ÿ 1: ç²å–è‚¡ç¥¨æ¸…å–®")
    
    tickers = get_hot_stocks(target_count, force_fallback=use_fallback)
    
    if not tickers or len(tickers) == 0:
        st.error("âŒ ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®")
        st.stop()
    
    # é¡¯ç¤ºè‚¡ç¥¨æ¸…å–®é è¦½
    with st.expander(f"ğŸ” æŸ¥çœ‹è‚¡ç¥¨æ¸…å–® ({len(tickers)} æª”)"):
        preview = [t.replace('.TW', '') for t in tickers[:50]]
        st.write(", ".join(preview))
        if len(tickers) > 50:
            st.write(f"... é‚„æœ‰ {len(tickers) - 50} æª”")
    
    # æ­¥é©Ÿ 2: ä¸‹è¼‰è‚¡ç¥¨è³‡æ–™
    st.subheader("ğŸ“¥ æ­¥é©Ÿ 2: ä¸‹è¼‰è‚¡ç¥¨è³‡æ–™")
    market_data = download_stock_data(tickers, period=data_period)
    
    if market_data is None:
        st.error("âŒ è³‡æ–™ä¸‹è¼‰å¤±æ•—")
        st.stop()
    
    # æ­¥é©Ÿ 3: è¨ˆç®—äº¤æ˜“å€¼
    st.subheader("ğŸ“Š æ­¥é©Ÿ 3: è¨ˆç®—äº¤æ˜“å€¼æŒ‡æ¨™")
    with st.spinner("æ­£åœ¨è¨ˆç®—..."):
        results, errors = calculate_trading_values(tickers, market_data)
    
    if not results:
        st.error("âŒ æœªèƒ½è¨ˆç®—å‡ºä»»ä½•æœ‰æ•ˆè³‡æ–™")
        st.info("**å¯èƒ½åŸå› ï¼š**")
        st.write("â€¢ æ‰€æœ‰è‚¡ç¥¨éƒ½æ²’æœ‰æœ€æ–°äº¤æ˜“è³‡æ–™")
        st.write("â€¢ ä»Šå¤©å¯èƒ½æ˜¯ä¼‘å¸‚æ—¥")
        st.write("â€¢ è³‡æ–™æ ¼å¼è§£æå¤±æ•—")
        
        if errors:
            with st.expander("æŸ¥çœ‹éŒ¯èª¤è©³æƒ…"):
                for err in errors[:20]:
                    st.text(err)
        st.stop()
    
    # è½‰æ›ç‚º DataFrame ä¸¦æ’åº
    df_results = pd.DataFrame(results)
    df_sorted = df_results.sort_values(by="äº¤æ˜“å€¼æŒ‡æ¨™", ascending=False)
    
    # å–å‰ 100 å
    top_n = min(100, len(df_sorted))
    df_top = df_sorted.head(top_n)
    
    # é¡¯ç¤ºçµæœ
    st.success(f"âœ… æˆåŠŸåˆ†æ {len(results)} æª”è‚¡ç¥¨ ({len(errors)} æª”å¤±æ•—)")
    
    # çµ±è¨ˆè³‡è¨Š
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æˆåŠŸåˆ†æ", f"{len(results)} æª”")
    with col2:
        st.metric("å‰ 100 å", f"{top_n} æª”")
    with col3:
        avg_value = df_top["äº¤æ˜“å€¼æŒ‡æ¨™"].mean()
        st.metric("å¹³å‡äº¤æ˜“å€¼", f"{avg_value:.2f} å„„")
    with col4:
        max_value = df_top["äº¤æ˜“å€¼æŒ‡æ¨™"].max()
        st.metric("æœ€é«˜äº¤æ˜“å€¼", f"{max_value:.2f} å„„")
    
    # é¡¯ç¤ºå‰ 100 åè¡¨æ ¼
    st.subheader(f"ğŸ“Š äº¤æ˜“å€¼å‰ {top_n} å")
    st.dataframe(df_top, use_container_width=True)
    
    # éŒ¯èª¤è³‡è¨Š
    if errors:
        with st.expander(f"âš ï¸ æŸ¥çœ‹å¤±æ•—è¨˜éŒ„ ({len(errors)} é …)"):
            for idx, err in enumerate(errors[:30], 1):
                st.text(f"{idx}. {err}")
    
    # æ­¥é©Ÿ 4: åŒæ­¥è‡³ Google Sheets
    st.subheader("â˜ï¸ æ­¥é©Ÿ 4: åŒæ­¥è‡³ Google Sheets")
    
    client = get_gspread_client()
    
    if client:
        try:
            with st.spinner("æ­£åœ¨å¯«å…¥é›²ç«¯..."):
                sh = client.open(SHEET_NAME)
                ws = sh.get_worksheet(0)
                
                # æª¢æŸ¥ä¸¦å¯«å…¥è¡¨é ­
                if not ws.acell('A1').value:
                    ws.append_row(["æ—¥æœŸ", "è‚¡ç¥¨ä»£è™Ÿ", "æ”¶ç›¤åƒ¹æ ¼", "äº¤æ˜“å€¼æŒ‡æ¨™"])
                
                # æº–å‚™ä¸Šå‚³è³‡æ–™ (åªä¸Šå‚³ A-D æ¬„)
                upload_list = df_top[["æ—¥æœŸ", "è‚¡ç¥¨ä»£è™Ÿ", "æ”¶ç›¤åƒ¹æ ¼", "äº¤æ˜“å€¼æŒ‡æ¨™"]].values.tolist()
                
                # æ‰¹æ¬¡å¯«å…¥
                ws.append_rows(upload_list)
                
                st.success(f"âœ… å·²æˆåŠŸåŒæ­¥ {top_n} ç­†è³‡æ–™è‡³ Google Sheetsï¼")
                st.info(f"ğŸ“„ å·¥ä½œè¡¨: {SHEET_NAME}")
                
        except Exception as e:
            st.error(f"âŒ Google Sheets åŒæ­¥å¤±æ•—: {e}")
            st.info("è³‡æ–™å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹è¡¨æ ¼ï¼Œæ‚¨å¯ä»¥æ‰‹å‹•è¤‡è£½ä½¿ç”¨")
    else:
        st.warning("âš ï¸ æœªé€£æ¥ Google Sheets")
        st.info("ğŸ’¡ è¨­å®š Streamlit Secrets æˆ–æœ¬åœ°æ†‘è­‰æª”æ¡ˆä»¥å•Ÿç”¨é›²ç«¯åŒæ­¥åŠŸèƒ½")

# å´é‚Šæ¬„èªªæ˜
with st.sidebar:
    st.header("â„¹ï¸ ä½¿ç”¨èªªæ˜")
    st.write("""
    **è³‡æ–™ä¾†æº:**
    - ä¸»è¦: Yahoo è‚¡å¸‚æˆäº¤å€¼æ’è¡Œæ¦œ
    - å‚™ç”¨: æ‰‹å‹•ç¶­è­·çš„ 100 æª”ç†±é–€è‚¡æ¸…å–®
    
    **åˆ†ææµç¨‹:**
    1. æŠ“å–ç†±é–€è‚¡ç¥¨ä»£è™Ÿ
    2. æ‰¹æ¬¡ä¸‹è¼‰è‚¡åƒ¹è³‡æ–™
    3. è¨ˆç®—äº¤æ˜“å€¼æŒ‡æ¨™ (åƒ¹æ ¼ Ã— æˆäº¤é‡)
    4. æ’åºä¸¦å–å‰ 100 å
    5. åŒæ­¥è‡³ Google Sheets
    
    **æ³¨æ„äº‹é …:**
    - å»ºè­°ä½¿ç”¨ 5d æˆ– 1mo æœŸé–“ä»¥ç²å–æœ€æ–°è³‡æ–™
    - ä¼‘å¸‚æ—¥å¯èƒ½ç„¡æ³•å–å¾—è³‡æ–™
    - é¦–æ¬¡åŸ·è¡Œå»ºè­°å…ˆæ¸¬è©¦è¼ƒå°æ•¸é‡
    """)
    
    st.header("ğŸ”§ å¥—ä»¶å®‰è£")
    st.write("åŸ·è¡Œæ­¤æŒ‡ä»¤å®‰è£æ‰€éœ€å¥—ä»¶:")
    st.code("pip install lxml beautifulsoup4 html5lib", language="bash")
