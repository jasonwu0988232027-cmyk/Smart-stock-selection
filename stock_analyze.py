import streamlit as st
import gspread
import pandas as pd
import yfinance as yf
import requests
import urllib3
import os
from datetime import datetime
from google.oauth2.service_account import Credentials

# --- åŸºç¤é…ç½® ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
SHEET_NAME = "Stock_Predictions_History"

def get_gspread_client():
    """å®‰å…¨æˆæ¬Šé‚è¼¯"""
    scopes = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive'
    ]
    
    # å„ªå…ˆå¾ Streamlit Secrets è®€å– (é›²ç«¯ç’°å¢ƒ)
    if "gcp_service_account" in st.secrets:
        try:
            creds_info = st.secrets["gcp_service_account"]
            creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
            return gspread.authorize(creds)
        except Exception as e:
            st.error(f"Cloud Auth Error: {e}")
            return None
    # æœ¬åœ°æ¸¬è©¦å‚™æ¡ˆ
    elif os.path.exists("eco-precept-485904-j5-7ef3cdda1b03.json"):
        creds = Credentials.from_service_account_file("eco-precept-485904-j5-7ef3cdda1b03.json", scopes=scopes)
        return gspread.authorize(creds)
    return None

@st.cache_data(ttl=86400)
def get_full_market_tickers():
    """æ“·å–å°è‚¡å…¨éƒ¨è‚¡ç¥¨ä»£ç¢¼"""
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    try:
        res = requests.get(url, timeout=10, verify=False, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'big5'
        df = pd.read_html(res.text)[0]
        df.columns = df.iloc[0]
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains("  ", na=False)]
        tickers = [f"{t.split('  ')[0].strip()}.TW" for t in df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'] if len(t.split('  ')[0].strip()) == 4]
        return tickers
    except:
        return [f"{i:04d}.TW" for i in range(1101, 2000)]

# --- UI èˆ‡ åŸ·è¡Œ ---
st.title("ğŸ† å°è‚¡å…¨å¸‚å ´äº¤æ˜“å€¼æ’è¡Œç³»çµ±")
st.write("ç›®æ¨™ï¼šæƒæå…¨å¸‚å ´æ¨™çš„ï¼Œç¯©é¸äº¤æ˜“å€¼å‰ 100 åä¸¦åŒæ­¥è‡³ Google Sheets A-D æ¬„ã€‚")

if st.button("ğŸš€ åŸ·è¡Œå…¨å¸‚å ´æƒæä¸¦åŒæ­¥"):
    all_tickers = get_full_market_tickers()
    client = get_gspread_client()
    
    if client:
        st.info(f"æ­£åœ¨åˆ†æå…¨å¸‚å ´ {len(all_tickers)} æª”è‚¡ç¥¨æ•¸æ“šï¼Œè«‹ç¨å€™...")
        all_market_data = []
        
        # ä½¿ç”¨åˆ†æ‰¹ä¸‹è¼‰æé«˜æ•ˆç‡
        batch_size = 50
        p_bar = st.progress(0)
        
        for i in range(0, len(all_tickers), batch_size):
            batch = all_tickers[i : i + batch_size]
            try:
                data = yf.download(batch, period="2d", group_by='ticker', threads=True, progress=False)
                
                for t in batch:
                    try:
                        t_df = data[t].dropna() if isinstance(data.columns, pd.MultiIndex) else data.dropna()
                        if not t_df.empty:
                            last_row = t_df.iloc[-1]
                            price = float(last_row['Close'])
                            vol = float(last_row['Volume'])
                            # è¨ˆç®—äº¤æ˜“å€¼æŒ‡æ¨™ (å„„)
                            val_billion = (price * vol) / 1e8
                            
                            all_market_data.append({
                                "æ—¥æœŸ": datetime.now().strftime('%Y-%m-%d'),
                                "è‚¡ç¥¨ä»£è™Ÿ": t,
                                "æ”¶ç›¤åƒ¹æ ¼": round(price, 2),
                                "äº¤æ˜“å€¼æŒ‡æ¨™": round(val_billion, 2)
                            })
                    except: continue
            except: continue
            p_bar.progress(min((i + batch_size) / len(all_tickers), 1.0))
        
        if all_market_data:
            # ä¾äº¤æ˜“å€¼æŒ‡æ¨™é™åºæ’åˆ—ï¼Œå–å‰ 100
            df_full = pd.DataFrame(all_market_data)
            df_top100 = df_full.sort_values(by="äº¤æ˜“å€¼æŒ‡æ¨™", ascending=False).head(100)
            
            # é¡¯ç¤ºçµæœ
            st.subheader("ğŸ“Š æœ¬æ—¥äº¤æ˜“å€¼å‰ 100 å (é è¦½)")
            st.dataframe(df_top100, use_container_width=True)
            
            # æº–å‚™ä¸Šå‚³è³‡æ–™ (è½‰æ›ç‚ºç¬¦åˆ A, B, C, D é †åºçš„ List)
            # é †åºï¼šæ—¥æœŸ, è‚¡ç¥¨ä»£è™Ÿ, æ”¶ç›¤åƒ¹æ ¼, äº¤æ˜“å€¼æŒ‡æ¨™
            upload_list = df_top100[["æ—¥æœŸ", "è‚¡ç¥¨ä»£è™Ÿ", "æ”¶ç›¤åƒ¹æ ¼", "äº¤æ˜“å€¼æŒ‡æ¨™"]].values.tolist()
            headers = ["æ—¥æœŸ", "è‚¡ç¥¨ä»£è™Ÿ", "æ”¶ç›¤åƒ¹æ ¼", "äº¤æ˜“å€¼æŒ‡æ¨™"]
            
            # å¯«å…¥ Google Sheets
            try:
                sh = client.open(SHEET_NAME)
                ws = sh.get_worksheet(0)
                
                # è‹¥å·¥ä½œè¡¨ç‚ºç©ºï¼Œå…ˆå¯«å…¥è¡¨é ­
                if not ws.acell('A1').value:
                    ws.append_row(headers)
                
                ws.append_rows(upload_list)
                st.success(f"âœ… å·²æˆåŠŸå°‡å‰ 100 åè³‡æ–™å¯«å…¥ Google Sheets A-D æ¬„ï¼")
            except Exception as e:
                st.error(f"é›²ç«¯å¯«å…¥å¤±æ•—: {e}")
        else:
            st.error("æƒæå¤±æ•—ï¼Œæœªå–å¾—ä»»ä½•æ•¸æ“šã€‚")
