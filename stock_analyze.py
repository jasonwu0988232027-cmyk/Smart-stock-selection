import streamlit as st
import gspread
import pandas as pd
import yfinance as yf
import requests
import urllib3
import os
import time
from datetime import datetime
from google.oauth2.service_account import Credentials

# --- åŸºç¤é…ç½® ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
SHEET_NAME = "Stock_Predictions_History"

def get_gspread_client():
    """å®‰å…¨æˆæ¬Šé‚è¼¯"""
    scopes = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive'
    ]
    
    # å„ªå…ˆå¾ Streamlit Secrets è®€å– (é›²ç«¯ç’°å¢ƒ)
    if "gcp_service_account" in st.secrets:
        try:
            creds_info = st.secrets["gcp_service_account"]
            creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
            return gspread.authorize(creds)
        except Exception as e:
            st.error(f"Cloud Auth Error: {e}")
            return None
    # æœ¬åœ°æ¸¬è©¦å‚™æ¡ˆ
    elif os.path.exists("eco-precept-485904-j5-7ef3cdda1b03.json"):
        creds = Credentials.from_service_account_file("eco-precept-485904-j5-7ef3cdda1b03.json", scopes=scopes)
        return gspread.authorize(creds)
    return None

@st.cache_data(ttl=86400)
def get_full_market_tickers():
    """æ­¥é©Ÿ 1-1ï¼šèª¿å–è‚¡ç¥¨å¸‚å ´å…¨éƒ¨çš„è‚¡ç¥¨ä»£ç¢¼"""
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    try:
        res = requests.get(url, timeout=10, verify=False, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'big5'
        df = pd.read_html(res.text)[0]
        df.columns = df.iloc[0]
        # åƒ…æ“·å– 4 ä½æ•¸ä»£ç¢¼çš„æ™®é€šè‚¡
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains("  ", na=False)]
        tickers = [f"{t.split('  ')[0].strip()}.TW" for t in df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'] if len(t.split('  ')[0].strip()) == 4]
        st.success(f"âœ… æˆåŠŸç²å– {len(tickers)} æª”è‚¡ç¥¨ä»£ç¢¼")
        return tickers
    except Exception as e:
        st.warning(f"âš ï¸ å¾è­‰äº¤æ‰€ç²å–è‚¡ç¥¨ä»£ç¢¼å¤±æ•—: {e}")
        st.info("ä½¿ç”¨é è¨­è‚¡ç¥¨ä»£ç¢¼ç¯„åœ...")
        # ä½¿ç”¨é è¨­ç¯„åœä½œç‚ºå‚™æ¡ˆ
        default_tickers = [f"{i:04d}.TW" for i in range(1101, 3000)]
        return default_tickers

# --- UI èˆ‡ åŸ·è¡Œ ---
st.title("ğŸ† å°è‚¡å…¨å¸‚å ´è³‡é‡‘æ’è¡Œç³»çµ± (å®Œæ•´ä¿®æ­£ç‰ˆ)")
st.write("æµç¨‹ï¼š1. æƒæå…¨å¸‚å ´ -> 2. ç¯©é¸äº¤æ˜“å€¼å‰ 100 å -> 3. åŒæ­¥è‡³ Google Sheets")

# è¨­å®šé¸é …
col1, col2 = st.columns(2)
with col1:
    test_mode = st.checkbox("ğŸ§ª æ¸¬è©¦æ¨¡å¼ (åƒ…æƒæ 50 æª”)", value=False)
with col2:
    batch_size = st.selectbox("æ‰¹æ¬¡å¤§å°", [25, 50, 100], index=1)

if st.button("ğŸš€ åŸ·è¡Œå…¨å¸‚å ´æ·±åº¦æƒæ"):
    with st.spinner("æ­£åœ¨ç²å–è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨..."):
        all_tickers = get_full_market_tickers()
    
    # æª¢æŸ¥æ˜¯å¦æˆåŠŸç²å–è‚¡ç¥¨ä»£ç¢¼
    if not all_tickers or len(all_tickers) == 0:
        st.error("âŒ ç„¡æ³•ç²å–è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨ï¼")
        st.info("**å¯èƒ½åŸå› ï¼š**")
        st.write("â€¢ ç„¡æ³•é€£æ¥å°ç£è­‰åˆ¸äº¤æ˜“æ‰€ç¶²ç«™")
        st.write("â€¢ ç¶²ç«™çµæ§‹å·²æ”¹è®Š")
        st.write("â€¢ ç¶²è·¯é€£ç·šå•é¡Œ")
        st.stop()
    
    # æ¸¬è©¦æ¨¡å¼ï¼šåƒ…è™•ç†å‰ 50 æª”
    if test_mode:
        all_tickers = all_tickers[:50]
        st.info(f"ğŸ§ª æ¸¬è©¦æ¨¡å¼ï¼šåƒ…æƒæå‰ {len(all_tickers)} æª”è‚¡ç¥¨")
    
    client = get_gspread_client()
    
    st.info(f"ğŸ“Š é–‹å§‹æƒæ {len(all_tickers)} æª”è‚¡ç¥¨...")
    all_market_results = []
    
    # è¨ºæ–·è³‡è¨Šå®¹å™¨
    error_log = []
    success_count = 0
    download_errors = 0
    
    # é€²åº¦è¿½è¹¤
    p_bar = st.progress(0)
    status_text = st.empty()
    
    # æ‰¹æ¬¡è™•ç†
    total_batches = (len(all_tickers) + batch_size - 1) // batch_size
    
    for batch_idx, i in enumerate(range(0, len(all_tickers), batch_size)):
        batch = all_tickers[i : i + batch_size]
        status_text.text(f"ğŸ“¥ æ­£åœ¨è™•ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} (è‚¡ç¥¨ {i+1}-{min(i+batch_size, len(all_tickers))})")
        
        try:
            # ä¸‹è¼‰ 5 å¤©è³‡æ–™ç¢ºä¿ç²å–æœ€æ–°äº¤æ˜“æ—¥
            data = yf.download(batch, period="5d", group_by='ticker', threads=True, progress=False)
            
            # æª¢æŸ¥æ˜¯å¦æˆåŠŸä¸‹è¼‰è³‡æ–™
            if data.empty:
                error_log.append(f"æ‰¹æ¬¡ {batch_idx + 1}: ä¸‹è¼‰è³‡æ–™ç‚ºç©º")
                download_errors += 1
                continue
            
            # è™•ç†æ¯ä¸€æ”¯è‚¡ç¥¨
            for t in batch:
                try:
                    # è™•ç†å¤šæ¨™çš„ä¸‹è¼‰çš„ DataFrame çµæ§‹
                    if len(batch) > 1 and isinstance(data.columns, pd.MultiIndex):
                        # å¤šæ¨™çš„æƒ…æ³
                        if t in data.columns.get_level_values(0):
                            t_df = data[t].dropna()
                        else:
                            error_log.append(f"{t}: æœªåœ¨ä¸‹è¼‰è³‡æ–™ä¸­")
                            continue
                    else:
                        # å–®æ¨™çš„æƒ…æ³
                        t_df = data.dropna()
                    
                    # æª¢æŸ¥è³‡æ–™æ˜¯å¦æœ‰æ•ˆ
                    if t_df.empty or len(t_df) == 0:
                        error_log.append(f"{t}: è³‡æ–™ç‚ºç©º")
                        continue
                    
                    last_row = t_df.iloc[-1]
                    
                    # æª¢æŸ¥å¿…è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
                    if 'Close' not in t_df.columns or 'Volume' not in t_df.columns:
                        error_log.append(f"{t}: ç¼ºå°‘å¿…è¦æ¬„ä½")
                        continue
                    
                    price = float(last_row['Close'])
                    vol = float(last_row['Volume'])
                    
                    # éæ¿¾ç„¡æ•ˆè³‡æ–™
                    if price <= 0 or vol <= 0:
                        error_log.append(f"{t}: åƒ¹æ ¼æˆ–æˆäº¤é‡ç„¡æ•ˆ")
                        continue
                    
                    # è¨ˆç®—äº¤æ˜“å€¼æŒ‡æ¨™ (å„„)
                    val_billion = (price * vol) / 1e8
                    
                    all_market_results.append({
                        "æ—¥æœŸ": datetime.now().strftime('%Y-%m-%d'),
                        "è‚¡ç¥¨ä»£è™Ÿ": t,
                        "æ”¶ç›¤åƒ¹æ ¼": round(price, 2),
                        "äº¤æ˜“å€¼æŒ‡æ¨™": round(val_billion, 4)
                    })
                    success_count += 1
                    
                except Exception as e:
                    error_log.append(f"{t}: {str(e)[:50]}")
                    continue
                    
        except Exception as e:
            error_msg = f"æ‰¹æ¬¡ {batch_idx + 1} ä¸‹è¼‰å¤±æ•—: {str(e)[:100]}"
            error_log.append(error_msg)
            st.warning(f"âš ï¸ {error_msg}")
            download_errors += 1
        
        # æ›´æ–°é€²åº¦
        progress = min((i + batch_size) / len(all_tickers), 1.0)
        p_bar.progress(progress)
        
        # æ¯æ‰¹æ¬¡å¾Œæš«åœ,é¿å… API é™åˆ¶
        if batch_idx < total_batches - 1:  # æœ€å¾Œä¸€æ‰¹ä¸éœ€è¦æš«åœ
            time.sleep(0.5)
    
    # æ¸…é™¤é€²åº¦é¡¯ç¤º
    p_bar.empty()
    status_text.empty()
    
    # é¡¯ç¤ºè¨ºæ–·è³‡è¨Š
    st.subheader("ğŸ“‹ æƒæè¨ºæ–·å ±å‘Š")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("âœ… æˆåŠŸæŠ“å–", f"{success_count} æª”")
    with col2:
        st.metric("âŒ å¤±æ•—æ•¸é‡", f"{len(error_log)} é …")
    with col3:
        success_rate = (success_count/len(all_tickers)*100) if len(all_tickers) > 0 else 0
        st.metric("ğŸ“ˆ æˆåŠŸç‡", f"{success_rate:.1f}%")
    with col4:
        st.metric("ğŸ”„ æ‰¹æ¬¡éŒ¯èª¤", f"{download_errors} æ‰¹")
    
    # é¡¯ç¤ºéŒ¯èª¤æ—¥èªŒé¸é …
    if error_log:
        with st.expander(f"âš ï¸ æŸ¥çœ‹éŒ¯èª¤è©³æƒ… ({len(error_log)} é …éŒ¯èª¤)"):
            st.write("**æœ€è¿‘ 30 é …éŒ¯èª¤ï¼š**")
            for idx, err in enumerate(error_log[:30], 1):
                st.text(f"{idx}. {err}")
    
    # --- æ­¥é©Ÿ 2ï¼šå–å¸‚å ´ä¸­ã€Œäº¤æ˜“å€¼æŒ‡æ¨™ã€å‰ 100 çš„è‚¡ç¥¨ ---
    if all_market_results:
        df_full = pd.DataFrame(all_market_results)
        # æ ¹æ“šäº¤æ˜“å€¼æŒ‡æ¨™é™åºæ’åˆ—ä¸¦å–å‰ 100
        top_n = min(100, len(df_full))
        df_top100 = df_full.sort_values(by="äº¤æ˜“å€¼æŒ‡æ¨™", ascending=False).head(top_n)
        
        st.success(f"âœ… æˆåŠŸåˆ†æ {len(df_full)} æª”è‚¡ç¥¨")
        st.subheader(f"ğŸ“Š å…¨å¸‚å ´äº¤æ˜“å€¼å‰ {top_n} åçµæœ")
        st.dataframe(df_top100, use_container_width=True)
        
        # æº–å‚™ä¸Šå‚³è³‡æ–™
        upload_list = df_top100[["æ—¥æœŸ", "è‚¡ç¥¨ä»£è™Ÿ", "æ”¶ç›¤åƒ¹æ ¼", "äº¤æ˜“å€¼æŒ‡æ¨™"]].values.tolist()
        
        # å¯«å…¥ Google Sheets
        if client:
            try:
                with st.spinner("æ­£åœ¨åŒæ­¥è‡³ Google Sheets..."):
                    sh = client.open(SHEET_NAME)
                    ws = sh.get_worksheet(0)
                    
                    # è‹¥ç‚ºç©ºè¡¨å‰‡å¯«å…¥è¡¨é ­
                    if not ws.acell('A1').value:
                        ws.append_row(["æ—¥æœŸ", "è‚¡ç¥¨ä»£è™Ÿ", "æ”¶ç›¤åƒ¹æ ¼", "äº¤æ˜“å€¼æŒ‡æ¨™"])
                    
                    ws.append_rows(upload_list)
                    st.success(f"âœ… å·²æˆåŠŸåŒæ­¥å‰ {top_n} åè‡³ Google Sheetsï¼")
            except Exception as e:
                st.error(f"âŒ Google Sheets å¯«å…¥å¤±æ•—: {e}")
                st.info("è³‡æ–™å·²é¡¯ç¤ºæ–¼ç¶²é ï¼Œæ‚¨å¯ä»¥æ‰‹å‹•è¤‡è£½ä½¿ç”¨")
        else:
            st.warning("âš ï¸ æœªé€£æ¥ Google Sheetsï¼Œè³‡æ–™åƒ…é¡¯ç¤ºæ–¼ç¶²é ")
            st.info("ğŸ’¡ æç¤ºï¼šè¨­å®š Streamlit Secrets æˆ–æœ¬åœ°æ†‘è­‰ä»¥å•Ÿç”¨é›²ç«¯åŒæ­¥")
    else:
        st.error("âŒ æœªèƒ½æˆåŠŸèª¿å–ä»»ä½•å¸‚å ´è³‡æ–™")
        st.info("**å»ºè­°è¨ºæ–·æ­¥é©Ÿï¼š**")
        st.write("1. âœ… ç¢ºèªç¶²è·¯é€£ç·šæ­£å¸¸")
        st.write("2. ğŸ§ª å…ˆå•Ÿç”¨ã€Œæ¸¬è©¦æ¨¡å¼ã€åƒ…æƒæ 50 æª”")
        st.write("3. ğŸ“Š æª¢æŸ¥æ˜¯å¦ç‚ºå°è‚¡ä¼‘å¸‚æ—¥")
        st.write("4. ğŸ”„ å˜—è©¦æ›´æ–° yfinance å¥—ä»¶: `pip install --upgrade yfinance`")
        st.write("5. ğŸ“ æŸ¥çœ‹ä¸Šæ–¹éŒ¯èª¤è©³æƒ…äº†è§£å…·é«”å•é¡Œ")
