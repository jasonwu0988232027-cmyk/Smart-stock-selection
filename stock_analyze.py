import streamlit as st
import gspread
import pandas as pd
import yfinance as yf
import requests
import urllib3
import os
import io
from datetime import datetime
from google.oauth2.service_account import Credentials

# --- åŸºç¤é…ç½® ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
SHEET_NAME = "Stock_Predictions_History"

def get_gspread_client():
    """å®‰å…¨æ€§æˆæ¬Šé‚è¼¯ï¼Œæ”¯æ´ Streamlit Secrets èˆ‡æœ¬åœ° JSON"""
    scopes = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive'
    ]
    
    if "gcp_service_account" in st.secrets:
        try:
            creds_info = st.secrets["gcp_service_account"]
            creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
            return gspread.authorize(creds)
        except Exception as e:
            st.error(f"Cloud Auth Error: {e}")
            return None
    elif os.path.exists("eco-precept-485904-j5-7ef3cdda1b03.json"):
        creds = Credentials.from_service_account_file("eco-precept-485904-j5-7ef3cdda1b03.json", scopes=scopes)
        return gspread.authorize(creds)
    return None

@st.cache_data(ttl=86400)
def get_full_market_tickers():
    """
    å¾è­‰äº¤æ‰€èª¿å–æ‰€æœ‰ä¸Šå¸‚è‚¡ç¥¨ä»£ç¢¼
    ä¿®æ­£é»ï¼šä½¿ç”¨ io.StringIO è§£æ±º pandas æ£„ç”¨è­¦å‘Š
    """
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    try:
        res = requests.get(url, timeout=10, verify=False, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'big5'
        # ä¿®æ­£ Future Warning: ä½¿ç”¨ io.StringIO åŒ…è£
        html_data = io.StringIO(res.text)
        df = pd.read_html(html_data)[0]
        
        df.columns = df.iloc[0]
        # ç¯©é¸æ¨™æº–ï¼šåŒ…å«å…©å€‹å…¨å½¢ç©ºæ ¼çš„é€šå¸¸æ˜¯è‚¡ç¥¨åç¨±é …ç›®
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains("  ", na=False)]
        raw_tickers = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split('  ').str[0].str.strip()
        # åƒ…å– 4 ä½æ•¸ä»£ç¢¼
        tickers = [f"{t}.TW" for t in raw_tickers if len(t) == 4]
        return tickers
    except Exception as e:
        st.error(f"Ticker Fetch Error: {e}")
        return [f"{i:04d}.TW" for i in range(1101, 1200)] # ç¸®å°å‚™æ´ç¯„åœé¿å…è¶…æ™‚

# --- UI èˆ‡ åŸ·è¡Œé‚è¼¯ ---
st.title("ğŸ† å°è‚¡å…¨å¸‚å ´è³‡é‡‘æ’è¡Œç³»çµ± (v2.1)")

if st.button("ğŸš€ åŸ·è¡Œå…¨å¸‚å ´æ·±åº¦æƒæ"):
    all_tickers = get_full_market_tickers()
    client = get_gspread_client()
    
    if client:
        st.info(f"æƒæé–‹å§‹ï¼šå…±è¨ˆ {len(all_tickers)} æª”æ¨™çš„")
        all_market_results = []
        p_bar = st.progress(0)
        status_text = st.empty()
        
        batch_size = 50 
        total_len = len(all_tickers)
        
        for i in range(0, total_len, batch_size):
            batch = all_tickers[i : i + batch_size]
            status_text.text(f"æ­£åœ¨åˆ†æç¬¬ {i} è‡³ {min(i+batch_size, total_len)} æª”...")
            
            try:
                # ä¸‹è¼‰è³‡æ–™
                data = yf.download(batch, period="2d", group_by='ticker', threads=True, progress=False)
                
                for t in batch:
                    try:
                        # æª¢æŸ¥æ¨™çš„æ˜¯å¦å­˜åœ¨æ–¼å›å‚³çµæœä¸­
                        if isinstance(data.columns, pd.MultiIndex):
                            if t not in data.columns.levels[0]: continue
                            t_df = data[t].dropna()
                        else:
                            t_df = data.dropna()
                            
                        if not t_df.empty and len(t_df) >= 1:
                            last_row = t_df.iloc[-1]
                            # ç¢ºä¿ Close èˆ‡ Volume å­˜åœ¨
                            price = float(last_row['Close'])
                            vol = float(last_row['Volume'])
                            val_billion = (price * vol) / 1e8
                            
                            all_market_results.append({
                                "æ—¥æœŸ": datetime.now().strftime('%Y-%m-%d'),
                                "è‚¡ç¥¨ä»£è™Ÿ": t,
                                "æ”¶ç›¤åƒ¹æ ¼": round(price, 2),
                                "äº¤æ˜“å€¼æŒ‡æ¨™": round(val_billion, 4)
                            })
                    except: continue
            except Exception as e:
                continue
            
            p_bar.progress(min((i + batch_size) / total_len, 1.0))
        
        # --- æ•¸æ“šæ’è¡Œèˆ‡ä¸Šå‚³ ---
        if all_market_results:
            df_full = pd.DataFrame(all_market_results)
            # æ’åºï¼šäº¤æ˜“å€¼ç”±é«˜åˆ°ä½
            df_top100 = df_full.sort_values(by="äº¤æ˜“å€¼æŒ‡æ¨™", ascending=False).head(100)
            
            st.subheader("ğŸ“Š ç•¶å‰å¸‚å ´æˆäº¤é‡‘é¡å‰ 100 å")
            st.dataframe(df_top100, use_container_width=True)
            
            try:
                sh = client.open(SHEET_NAME)
                ws = sh.get_worksheet(0)
                
                # è‡ªå‹•æª¢æŸ¥èˆ‡å¯«å…¥è¡¨é ­
                header = ["æ—¥æœŸ", "è‚¡ç¥¨ä»£è™Ÿ", "æ”¶ç›¤åƒ¹æ ¼", "äº¤æ˜“å€¼æŒ‡æ¨™"]
                if not ws.acell('A1').value:
                    ws.append_row(header)
                
                # ä¸Šå‚³è³‡æ–™
                ws.append_rows(df_top100[header].values.tolist())
                st.success(f"âœ… å·²æˆåŠŸåˆ†æä¸¦åŒæ­¥ {len(df_top100)} ç­†æ•¸æ“šè‡³é›²ç«¯")
            except Exception as e:
                st.error(f"Google Sheets å¯«å…¥ç•°å¸¸: {e}")
        else:
            st.error("æƒæå®Œæˆä½†æœªç²å–æœ‰æ•ˆæ•¸æ“šã€‚")
