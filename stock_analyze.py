import streamlit as st
import gspread
import pandas as pd
import yfinance as yf
import requests
import urllib3
import os
from datetime import datetime
from google.oauth2.service_account import Credentials

# --- åŸºç¤é…ç½® ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
SHEET_NAME = "Stock_Predictions_History"

def get_gspread_client():
    """å®‰å…¨æ€§æˆæ¬Šé‚è¼¯ï¼Œæ”¯æ´ Streamlit Secrets èˆ‡æœ¬åœ° JSON"""
    scopes = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive'
    ]
    
    if "gcp_service_account" in st.secrets:
        try:
            creds_info = st.secrets["gcp_service_account"]
            creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
            return gspread.authorize(creds)
        except Exception as e:
            st.error(f"Cloud Auth Error: {e}")
            return None
    elif os.path.exists("eco-precept-485904-j5-7ef3cdda1b03.json"):
        creds = Credentials.from_service_account_file("eco-precept-485904-j5-7ef3cdda1b03.json", scopes=scopes)
        return gspread.authorize(creds)
    return None

@st.cache_data(ttl=86400)
def get_full_market_tickers():
    """
    å¾è­‰äº¤æ‰€èª¿å–æ‰€æœ‰ä¸Šå¸‚è‚¡ç¥¨ä»£ç¢¼
    éæ¿¾æ¢ä»¶ï¼šåƒ…ä¿ç•™ 4 ä½æ•¸ä»£ç¢¼ä¹‹æ™®é€šè‚¡
    """
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    try:
        res = requests.get(url, timeout=10, verify=False, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'big5'
        df = pd.read_html(res.text)[0]
        df.columns = df.iloc[0]
        # ç¯©é¸ä»£ç¢¼èˆ‡åç¨±æ¬„ä½ï¼Œä¸¦éæ¿¾å‡ºæ¨™æº– 4 ä½æ•¸ä»£ç¢¼
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains("  ", na=False)]
        raw_tickers = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split('  ').str[0].str.strip()
        tickers = [f"{t}.TW" for t in raw_tickers if len(t) == 4]
        return tickers
    except Exception as e:
        st.error(f"Ticker Fetch Error: {e}")
        # å‚™æ´æ©Ÿåˆ¶ï¼šè¿”å›å¸¸ç”¨ç¯„åœï¼ˆä¸å»ºè­°é•·æœŸä¾è³´ï¼‰
        return [f"{i:04d}.TW" for i in range(1101, 9999)]

# --- UI èˆ‡ åŸ·è¡Œé‚è¼¯ ---
st.title("ğŸ† å°è‚¡å…¨å¸‚å ´è³‡é‡‘æ’è¡Œç³»çµ±")
st.markdown("""
**åŠŸèƒ½èªªæ˜**ï¼š
1. ç²å–å…¨å¸‚å ´ï¼ˆç´„ 1000+ æª”ï¼‰ä»£ç¢¼ã€‚
2. åˆ†æ‰¹æŠ“å–æœ€æ–° 2 æ—¥äº¤æ˜“æ•¸æ“šã€‚
3. è¨ˆç®— **æ”¶ç›¤åƒ¹ Ã— æˆäº¤é‡**ï¼ˆäº¤æ˜“å€¼ï¼‰ã€‚
4. ç¯©é¸å…¨å¸‚å ´å‰ 100 åä¸¦ä¸Šå‚³ã€‚
""")

if st.button("ğŸš€ åŸ·è¡Œå…¨å¸‚å ´æ·±åº¦æƒæ"):
    all_tickers = get_full_market_tickers()
    client = get_gspread_client()
    
    if client:
        st.info(f"æƒæé–‹å§‹ï¼šå…±è¨ˆ {len(all_tickers)} æª”æ¨™çš„")
        all_market_results = []
        p_bar = st.progress(0)
        status_text = st.empty()
        
        batch_size = 50  # ç¸®å°æ‰¹æ¬¡å¤§å°ä»¥æé«˜ yfinance ç©©å®šæ€§
        total_len = len(all_tickers)
        
        for i in range(0, total_len, batch_size):
            batch = all_tickers[i : i + batch_size]
            status_text.text(f"æ­£åœ¨åˆ†æç¬¬ {i} è‡³ {min(i+batch_size, total_len)} æª”...")
            
            try:
                # ä¸‹è¼‰æœ€æ–° 2 å¤©è³‡æ–™ï¼Œthreads=True åŠ é€Ÿä¸‹è¼‰
                data = yf.download(batch, period="2d", group_by='ticker', threads=True, progress=False)
                
                for t in batch:
                    try:
                        # è™•ç† DataFrame çµæ§‹
                        if t in data.columns.levels[0]:
                            t_df = data[t].dropna()
                        else:
                            continue
                            
                        if not t_df.empty:
                            last_row = t_df.iloc[-1]
                            price = float(last_row['Close'])
                            vol = float(last_row['Volume'])
                            # è¨ˆç®—äº¤æ˜“å€¼æŒ‡æ¨™ (å–®ä½ï¼šå„„å°å¹£)
                            val_billion = (price * vol) / 100000000
                            
                            all_market_results.append({
                                "æ—¥æœŸ": datetime.now().strftime('%Y-%m-%d'),
                                "è‚¡ç¥¨ä»£è™Ÿ": t,
                                "æ”¶ç›¤åƒ¹æ ¼": round(price, 2),
                                "äº¤æ˜“å€¼æŒ‡æ¨™": round(val_billion, 4)
                            })
                    except:
                        continue
            except Exception as e:
                st.warning(f"æ‰¹æ¬¡ {i} ç™¼ç”Ÿè·³è½‰ï¼š{e}")
                continue
            
            p_bar.progress(min((i + batch_size) / total_len, 1.0))
        
        # --- æ•¸æ“šè™•ç†èˆ‡ä¸Šå‚³ ---
        if all_market_results:
            df_full = pd.DataFrame(all_market_results)
            df_top100 = df_full.sort_values(by="äº¤æ˜“å€¼æŒ‡æ¨™", ascending=False).head(100)
            
            st.subheader("ğŸ“Š ç•¶å‰å¸‚å ´æˆäº¤é‡‘é¡å‰ 100 å")
            st.dataframe(df_top100, use_container_width=True)
            
            try:
                sh = client.open(SHEET_NAME)
                ws = sh.get_worksheet(0)
                
                # åˆå§‹åŒ–è¡¨é ­
                if not ws.acell('A1').value:
                    ws.append_row(["æ—¥æœŸ", "è‚¡ç¥¨ä»£è™Ÿ", "æ”¶ç›¤åƒ¹æ ¼", "äº¤æ˜“å€¼æŒ‡æ¨™"])
                
                # æ‰¹æ¬¡å¯«å…¥è³‡æ–™
                upload_data = df_top100.values.tolist()
                ws.append_rows(upload_data)
                st.success("âœ… æ•¸æ“šå·²æˆåŠŸåŒæ­¥è‡³ Google Sheets A-D æ¬„ä½")
            except Exception as e:
                st.error(f"Google Sheets å¯«å…¥ç•°å¸¸: {e}")
        else:
            st.error("æœªèƒ½æˆåŠŸèª¿å–å¸‚å ´è³‡æ–™ï¼Œè«‹æª¢æŸ¥ API é™åˆ¶æˆ–ç¶²è·¯ç‹€æ…‹ã€‚")
