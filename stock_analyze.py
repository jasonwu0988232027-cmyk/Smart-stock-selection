import streamlit as st
import gspread
import pandas as pd
import yfinance as yf
import requests
import urllib3
import os
from io import StringIO
from datetime import datetime
import pytz
from google.oauth2.service_account import Credentials

# --- åŸºç¤é…ç½® ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
SHEET_NAME = "Stock_Predictions_History"
TAIWAN_TZ = pytz.timezone('Asia/Taipei')

def get_gspread_client():
    """å®‰å…¨æˆæ¬Šé‚è¼¯"""
    scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
    try:
        if "gcp_service_account" in st.secrets:
            creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=scopes)
            return gspread.authorize(creds)
        elif os.path.exists("credentials.json"):
            creds = Credentials.from_service_account_file("credentials.json", scopes=scopes)
            return gspread.authorize(creds)
    except Exception as e:
        st.error(f"æˆæ¬Šå¤±æ•—: {e}")
    return None

@st.cache_data(ttl=86400)
def get_full_market_tickers():
    """èª¿å–å°ç£ä¸Šå¸‚è‚¡ç¥¨ä»£ç¢¼ (å«å‚™æ´é‚è¼¯)"""
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    try:
        res = requests.get(url, timeout=10, verify=False, headers=headers)
        res.encoding = 'big5'
        # ä½¿ç”¨ StringIO ä¿®å¾© FutureWarning
        df = pd.read_html(StringIO(res.text))[0]
        df.columns = df.iloc[0]
        # ç¯©é¸å››ä½æ•¸æ™®é€šè‚¡
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains("  ", na=False)]
        tickers = [f"{t.split('  ')[0].strip()}.TW" for t in df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'] 
                   if len(t.split('  ')[0].strip()) == 4]
        return tickers
    except Exception as e:
        st.warning(f"è­‰äº¤æ‰€é€£ç·šå¤±æ•—ï¼Œå•Ÿå‹•å‚™æ´æ©Ÿåˆ¶ã€‚éŒ¯èª¤: {e}")
        # è‡³å°‘è¿”å›æ¬Šå€¼è‚¡åå–®ç¢ºä¿ç³»çµ±ä¸å´©æ½°
        return ["2330.TW", "2317.TW", "2454.TW", "2303.TW", "2881.TW"]

# --- UI èˆ‡ åŸ·è¡Œ ---
st.set_page_config(page_title="å°è‚¡å…¨å¸‚å ´ç›£æ§", layout="wide")
st.title("ğŸ† å°è‚¡å…¨å¸‚å ´è³‡é‡‘æ’è¡Œç³»çµ±")

if st.button("ğŸš€ åŸ·è¡Œå…¨å¸‚å ´æ·±åº¦æƒæ"):
    all_tickers = get_full_market_tickers()
    client = get_gspread_client()
    
    if client and all_tickers:
        st.info(f"åµæ¸¬åˆ° {len(all_tickers)} æª”è‚¡ç¥¨ï¼Œé–‹å§‹åˆ†æ‰¹ä¸‹è¼‰è¡Œæƒ…...")
        all_market_results = []
        p_bar = st.progress(0)
        status_text = st.empty()
        
        # ç¸®å°æ‰¹æ¬¡ä»¥æå‡ç©©å®šæ€§ï¼Œå¢åŠ  threads ä»¥æå‡é€Ÿåº¦
        batch_size = 50 
        today_str = datetime.now(TAIWAN_TZ).strftime('%Y-%m-%d')
        
        for i in range(0, len(all_tickers), batch_size):
            batch = all_tickers[i : i + batch_size]
            status_text.text(f"æ­£åœ¨åˆ†æ: {i} ~ {min(i+batch_size, len(all_tickers))} æª”...")
            
            try:
                # å¢åŠ  period å¯¬åº¦è‡³ 5dï¼Œç¢ºä¿è·¨é€±æœ«æ™‚èƒ½æŠ“åˆ°è³‡æ–™
                data = yf.download(batch, period="5d", interval="1d", group_by='ticker', threads=True, progress=False)
                
                for t in batch:
                    try:
                        # æª¢æŸ¥è‚¡ç¥¨æ˜¯å¦å­˜åœ¨æ–¼ä¸‹è¼‰çµæœä¸­
                        if isinstance(data.columns, pd.MultiIndex):
                            if t not in data.columns.levels[0]: continue
                            t_df = data[t].dropna()
                        else:
                            t_df = data.dropna()
                            
                        if not t_df.empty:
                            last_row = t_df.iloc[-1]
                            price = float(last_row['Close'])
                            vol = float(last_row['Volume'])
                            # éæ¿¾æ‰ç„¡æˆäº¤é‡çš„è³‡æ–™ (å¦‚åœç‰Œ)
                            if vol <= 0: continue 
                            
                            val_billion = (price * vol) / 1e8
                            all_market_results.append({
                                "æ—¥æœŸ": today_str,
                                "è‚¡ç¥¨ä»£è™Ÿ": t,
                                "æ”¶ç›¤åƒ¹æ ¼": round(price, 2),
                                "äº¤æ˜“å€¼æŒ‡æ¨™": round(val_billion, 4)
                            })
                    except: continue
            except Exception as e:
                st.warning(f"æ‰¹æ¬¡ä¸‹è¼‰ä¸­æ–·: {e}")
            
            p_bar.progress(min((i + batch_size) / len(all_tickers), 1.0))
        
        # --- è³‡æ–™è™•ç†èˆ‡å¯«å…¥ ---
        if all_market_results:
            df_full = pd.DataFrame(all_market_results)
            df_top100 = df_full.sort_values(by="äº¤æ˜“å€¼æŒ‡æ¨™", ascending=False).head(100)
            
            st.subheader(f"ğŸ“Š {today_str} äº¤æ˜“å€¼å‰ 100 åçµæœ")
            st.dataframe(df_top100, use_container_width=True)
            
            try:
                sh = client.open(SHEET_NAME)
                ws = sh.get_worksheet(0)
                
                # æ›´æ–°æ©Ÿåˆ¶ï¼šç²å–è¡¨é ­ï¼Œè‹¥ç„¡å‰‡å¯«å…¥
                if ws.row_count == 0 or not ws.acell('A1').value:
                    ws.update('A1:D1', [["æ—¥æœŸ", "è‚¡ç¥¨ä»£è™Ÿ", "æ”¶ç›¤åƒ¹æ ¼", "äº¤æ˜“å€¼æŒ‡æ¨™"]])
                
                # æº–å‚™ä¸Šå‚³è³‡æ–™
                upload_data = df_top100[["æ—¥æœŸ", "è‚¡ç¥¨ä»£è™Ÿ", "æ”¶ç›¤åƒ¹æ ¼", "äº¤æ˜“å€¼æŒ‡æ¨™"]].values.tolist()
                ws.append_rows(upload_data)
                
                status_text.empty()
                st.success(f"âœ… å·²æˆåŠŸç¯©é¸å‰ 100 åä¸¦åŒæ­¥è‡³ Google Sheetsï¼")
            except Exception as e:
                st.error(f"Google Sheets å¯«å…¥ç•°å¸¸: {e}")
        else:
            st.error("âŒ æƒæå®Œæˆä½†æ•¸æ“šé›†ç‚ºç©ºã€‚åŸå› å¯èƒ½æ˜¯ï¼šYahoo Finance é˜»æ“‹æˆ–éäº¤æ˜“æ™‚æ®µç„¡æ•¸æ“šã€‚")
    else:
        st.error("ç„¡æ³•åˆå§‹åŒ– API å®¢æˆ¶ç«¯æˆ–ç²å–è‚¡ç¥¨æ¸…å–®ã€‚")
